# Code for the paper titled "Efficient Quantization of Mixture-of-Experts with Theoretical Generalization Guarantees" [ICLR'2026]
Code for post-training weight quantization of large MoE models
